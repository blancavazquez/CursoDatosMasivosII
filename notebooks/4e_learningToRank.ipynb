{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    },
    "colab": {
      "name": "4e_learningToRank.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/blancavazquez/CursoDatosMasivosII/blob/master/notebooks/4e_learningToRank.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZbM6Jzkbem4q"
      },
      "source": [
        "## Algoritmos learning to rank\n",
        "\n",
        "El objetivo de esta libreta es estudiar los algoritmos de learning to rank en sistemas de recomendación\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lB2Z-XlKem4u"
      },
      "source": [
        "## RankNet"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8DI5uftxem4u"
      },
      "source": [
        "import keras\n",
        "from keras import backend as K\n",
        "from keras.layers import Activation, Dense, Input, Subtract\n",
        "from keras.models import Model\n",
        "import random\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9ZIYP3bVem4w",
        "outputId": "b140e32f-b73b-4c48-ccfe-d143edc8c901"
      },
      "source": [
        "\"\"\"Generación de datos dummies\"\"\"\n",
        "INPUT_DIM = 3\n",
        "\n",
        "#se definen los objetos a comparar\n",
        "X1 = 2 * np.random.uniform(size=(50, INPUT_DIM)) #Objeto 1\n",
        "X2 = np.random.uniform(size=(50, INPUT_DIM)) #Objeto 2\n",
        "Y = [random.randint(0,1) for _ in range(50)]\n",
        "\n",
        "print(\"Tamaño de X1\",X1.shape)\n",
        "print(\"Tamaño de X2\",X2.shape)\n",
        "print(\"Tamaño de Y\",len(Y))"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tamaño de X1 (50, 3)\n",
            "Tamaño de X2 (50, 3)\n",
            "Tamaño de Y 50\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2XIGpnstem4y"
      },
      "source": [
        "# Transformación de los datos\n",
        "mms = MinMaxScaler() #default=(0, 1)\n",
        "mms.fit(np.concatenate((X1, X2), axis=0))\n",
        "X1 = mms.transform(X1)\n",
        "X2 = mms.transform(X2)\n",
        "Y = np.asarray(Y)"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "PsHGiq3kmJrR",
        "outputId": "61465a8f-d5ab-4fc8-8457-f0d532b0cf94"
      },
      "source": [
        "#Visualizando la entrada\n",
        "df_input = pd.DataFrame(X1, columns = ['Feature1', 'Feature2', 'Feature3'])\n",
        "df_input"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Feature1</th>\n",
              "      <th>Feature2</th>\n",
              "      <th>Feature3</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.602928</td>\n",
              "      <td>0.914066</td>\n",
              "      <td>0.358997</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.646086</td>\n",
              "      <td>0.029447</td>\n",
              "      <td>0.447552</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.773208</td>\n",
              "      <td>0.722852</td>\n",
              "      <td>0.400753</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.056823</td>\n",
              "      <td>0.597731</td>\n",
              "      <td>0.777838</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.307797</td>\n",
              "      <td>0.188917</td>\n",
              "      <td>0.301281</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>0.952882</td>\n",
              "      <td>0.229861</td>\n",
              "      <td>0.907204</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>0.548913</td>\n",
              "      <td>0.320591</td>\n",
              "      <td>0.118644</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.856186</td>\n",
              "      <td>0.605745</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>0.617706</td>\n",
              "      <td>0.688277</td>\n",
              "      <td>0.651821</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>0.832962</td>\n",
              "      <td>0.465915</td>\n",
              "      <td>0.805833</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>0.778812</td>\n",
              "      <td>0.771267</td>\n",
              "      <td>0.980535</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>0.179487</td>\n",
              "      <td>0.158618</td>\n",
              "      <td>0.703173</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>0.494997</td>\n",
              "      <td>0.427218</td>\n",
              "      <td>0.678361</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>0.951104</td>\n",
              "      <td>0.926628</td>\n",
              "      <td>0.533493</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>0.480825</td>\n",
              "      <td>0.787886</td>\n",
              "      <td>0.963149</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>0.404654</td>\n",
              "      <td>0.366451</td>\n",
              "      <td>0.529647</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>0.818697</td>\n",
              "      <td>0.242414</td>\n",
              "      <td>0.534625</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>0.035273</td>\n",
              "      <td>0.252816</td>\n",
              "      <td>0.373988</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>0.631155</td>\n",
              "      <td>0.650136</td>\n",
              "      <td>0.945651</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>0.762323</td>\n",
              "      <td>0.880116</td>\n",
              "      <td>0.119728</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>0.211897</td>\n",
              "      <td>0.181104</td>\n",
              "      <td>0.767563</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>0.573735</td>\n",
              "      <td>0.109467</td>\n",
              "      <td>0.611842</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>0.248831</td>\n",
              "      <td>0.335709</td>\n",
              "      <td>0.217753</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>0.164790</td>\n",
              "      <td>0.361421</td>\n",
              "      <td>0.632027</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24</th>\n",
              "      <td>0.986715</td>\n",
              "      <td>0.330318</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25</th>\n",
              "      <td>0.076885</td>\n",
              "      <td>0.691867</td>\n",
              "      <td>0.507349</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26</th>\n",
              "      <td>0.320993</td>\n",
              "      <td>0.301886</td>\n",
              "      <td>0.937115</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27</th>\n",
              "      <td>0.454450</td>\n",
              "      <td>0.624998</td>\n",
              "      <td>0.527227</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28</th>\n",
              "      <td>0.345260</td>\n",
              "      <td>0.192040</td>\n",
              "      <td>0.500868</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29</th>\n",
              "      <td>0.831415</td>\n",
              "      <td>0.000007</td>\n",
              "      <td>0.939986</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30</th>\n",
              "      <td>0.099630</td>\n",
              "      <td>0.552948</td>\n",
              "      <td>0.318851</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>31</th>\n",
              "      <td>0.145176</td>\n",
              "      <td>0.850213</td>\n",
              "      <td>0.080792</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>32</th>\n",
              "      <td>0.800720</td>\n",
              "      <td>0.498751</td>\n",
              "      <td>0.623495</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>33</th>\n",
              "      <td>0.615323</td>\n",
              "      <td>0.290227</td>\n",
              "      <td>0.908878</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>34</th>\n",
              "      <td>0.556769</td>\n",
              "      <td>0.250228</td>\n",
              "      <td>0.349269</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>35</th>\n",
              "      <td>0.548540</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.431521</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>36</th>\n",
              "      <td>0.670217</td>\n",
              "      <td>0.363857</td>\n",
              "      <td>0.119570</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>37</th>\n",
              "      <td>0.395530</td>\n",
              "      <td>0.021237</td>\n",
              "      <td>0.112102</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>38</th>\n",
              "      <td>0.870851</td>\n",
              "      <td>0.029623</td>\n",
              "      <td>0.391788</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>39</th>\n",
              "      <td>0.162264</td>\n",
              "      <td>0.844219</td>\n",
              "      <td>0.524157</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>40</th>\n",
              "      <td>0.690985</td>\n",
              "      <td>0.534569</td>\n",
              "      <td>0.143855</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>41</th>\n",
              "      <td>0.419696</td>\n",
              "      <td>0.084753</td>\n",
              "      <td>0.489592</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>42</th>\n",
              "      <td>0.162477</td>\n",
              "      <td>0.335619</td>\n",
              "      <td>0.373259</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>43</th>\n",
              "      <td>0.179552</td>\n",
              "      <td>0.447735</td>\n",
              "      <td>0.746546</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>44</th>\n",
              "      <td>0.346798</td>\n",
              "      <td>0.735911</td>\n",
              "      <td>0.463311</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>45</th>\n",
              "      <td>0.530854</td>\n",
              "      <td>0.561381</td>\n",
              "      <td>0.696658</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>46</th>\n",
              "      <td>0.359699</td>\n",
              "      <td>0.015258</td>\n",
              "      <td>0.558739</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>47</th>\n",
              "      <td>0.025031</td>\n",
              "      <td>0.713870</td>\n",
              "      <td>0.521582</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>48</th>\n",
              "      <td>0.290748</td>\n",
              "      <td>0.777173</td>\n",
              "      <td>0.760494</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>49</th>\n",
              "      <td>0.005690</td>\n",
              "      <td>0.919230</td>\n",
              "      <td>0.146163</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    Feature1  Feature2  Feature3\n",
              "0   0.602928  0.914066  0.358997\n",
              "1   0.646086  0.029447  0.447552\n",
              "2   0.773208  0.722852  0.400753\n",
              "3   0.056823  0.597731  0.777838\n",
              "4   0.307797  0.188917  0.301281\n",
              "5   0.952882  0.229861  0.907204\n",
              "6   0.548913  0.320591  0.118644\n",
              "7   1.000000  0.856186  0.605745\n",
              "8   0.617706  0.688277  0.651821\n",
              "9   0.832962  0.465915  0.805833\n",
              "10  0.778812  0.771267  0.980535\n",
              "11  0.179487  0.158618  0.703173\n",
              "12  0.494997  0.427218  0.678361\n",
              "13  0.951104  0.926628  0.533493\n",
              "14  0.480825  0.787886  0.963149\n",
              "15  0.404654  0.366451  0.529647\n",
              "16  0.818697  0.242414  0.534625\n",
              "17  0.035273  0.252816  0.373988\n",
              "18  0.631155  0.650136  0.945651\n",
              "19  0.762323  0.880116  0.119728\n",
              "20  0.211897  0.181104  0.767563\n",
              "21  0.573735  0.109467  0.611842\n",
              "22  0.248831  0.335709  0.217753\n",
              "23  0.164790  0.361421  0.632027\n",
              "24  0.986715  0.330318  1.000000\n",
              "25  0.076885  0.691867  0.507349\n",
              "26  0.320993  0.301886  0.937115\n",
              "27  0.454450  0.624998  0.527227\n",
              "28  0.345260  0.192040  0.500868\n",
              "29  0.831415  0.000007  0.939986\n",
              "30  0.099630  0.552948  0.318851\n",
              "31  0.145176  0.850213  0.080792\n",
              "32  0.800720  0.498751  0.623495\n",
              "33  0.615323  0.290227  0.908878\n",
              "34  0.556769  0.250228  0.349269\n",
              "35  0.548540  1.000000  0.431521\n",
              "36  0.670217  0.363857  0.119570\n",
              "37  0.395530  0.021237  0.112102\n",
              "38  0.870851  0.029623  0.391788\n",
              "39  0.162264  0.844219  0.524157\n",
              "40  0.690985  0.534569  0.143855\n",
              "41  0.419696  0.084753  0.489592\n",
              "42  0.162477  0.335619  0.373259\n",
              "43  0.179552  0.447735  0.746546\n",
              "44  0.346798  0.735911  0.463311\n",
              "45  0.530854  0.561381  0.696658\n",
              "46  0.359699  0.015258  0.558739\n",
              "47  0.025031  0.713870  0.521582\n",
              "48  0.290748  0.777173  0.760494\n",
              "49  0.005690  0.919230  0.146163"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kg-bWpcVem4x"
      },
      "source": [
        "def RankNet_model(input_shape):\n",
        "    \"\"\"Construcción de la red neuronal\"\"\"\n",
        "    h1 = Dense(4, activation=\"relu\", name='Relu_layer1') #red completamente conectada\n",
        "    h2 = Dense(2, activation='relu', name='Relu_layer2')\n",
        "    h3 = Dense(1, activation='linear', name='Identity_layer')\n",
        "    # Objeto 1 a comparar\n",
        "    input1 = Input(shape=(input_shape,), name='Input_layer1')\n",
        "    x1 = h1(input1)\n",
        "    x1 = h2(x1)\n",
        "    x1 = h3(x1)\n",
        "    # Objeto 2 a comparar\n",
        "    input2 = Input(shape=(input_shape,), name='Input_layer2')\n",
        "    x2 = h1(input2)\n",
        "    x2 = h2(x2)\n",
        "    x2 = h3(x2)\n",
        "    # Capa de comparación\n",
        "    subtracted = Subtract(name='Subtract_layer')([x1, x2])\n",
        "    # Función de activación\n",
        "    out = Activation('sigmoid', name='Activation_layer')(subtracted)\n",
        "    # Modelo\n",
        "    model = Model(inputs=[input1, input2], outputs=out)\n",
        "    return model"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GRPDymtBem4x",
        "outputId": "9f74dff2-c4ba-42f7-aa22-14211a6329bd"
      },
      "source": [
        "model = RankNet_model(INPUT_DIM)\n",
        "print(model.summary())"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "Input_layer1 (InputLayer)       [(None, 3)]          0                                            \n",
            "__________________________________________________________________________________________________\n",
            "Input_layer2 (InputLayer)       [(None, 3)]          0                                            \n",
            "__________________________________________________________________________________________________\n",
            "Relu_layer1 (Dense)             (None, 4)            16          Input_layer1[0][0]               \n",
            "                                                                 Input_layer2[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "Relu_layer2 (Dense)             (None, 2)            10          Relu_layer1[0][0]                \n",
            "                                                                 Relu_layer1[1][0]                \n",
            "__________________________________________________________________________________________________\n",
            "Identity_layer (Dense)          (None, 1)            3           Relu_layer2[0][0]                \n",
            "                                                                 Relu_layer2[1][0]                \n",
            "__________________________________________________________________________________________________\n",
            "Subtract_layer (Subtract)       (None, 1)            0           Identity_layer[0][0]             \n",
            "                                                                 Identity_layer[1][0]             \n",
            "__________________________________________________________________________________________________\n",
            "Activation_layer (Activation)   (None, 1)            0           Subtract_layer[0][0]             \n",
            "==================================================================================================\n",
            "Total params: 29\n",
            "Trainable params: 29\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n",
            "None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t1-ubJa3em4y",
        "outputId": "fbb987b9-86fc-4d2a-aaa7-92132fb802f0"
      },
      "source": [
        "# Entrenamiento del modelo\n",
        "model.compile(optimizer=\"adam\", loss=\"binary_crossentropy\")\n",
        "model.fit([X1,X2], Y, batch_size=10, epochs=5, verbose=1)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 0.6931\n",
            "Epoch 2/5\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 0.6931\n",
            "Epoch 3/5\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 0.6930\n",
            "Epoch 4/5\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 0.6930\n",
            "Epoch 5/5\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 0.6930\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f83f68ac890>"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SEkirMRygY91"
      },
      "source": [
        "#Salida del modelo\n",
        "get_ranker_output = K.function([model.layers[0].input], [model.layers[-3].get_output_at(0)])\n",
        "Ranker_output = get_ranker_output([X1])[0]"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "gRw165gimRDZ",
        "outputId": "73966bc9-c1f1-413b-aab8-f247ecc4849e"
      },
      "source": [
        "#Visualizando la salida\n",
        "df_output = pd.DataFrame(Ranker_output, columns = ['score'])\n",
        "df_output"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>score</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.007252</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.013396</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.014913</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.002265</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>0.002011</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>0.018354</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>0.016569</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>0.001047</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>0.005303</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>0.000642</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>0.016382</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>0.016178</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>0.023111</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>0.001396</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24</th>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25</th>\n",
              "      <td>0.007167</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26</th>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27</th>\n",
              "      <td>0.001047</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28</th>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29</th>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30</th>\n",
              "      <td>0.006040</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>31</th>\n",
              "      <td>0.009930</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>32</th>\n",
              "      <td>0.010082</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>33</th>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>34</th>\n",
              "      <td>0.011088</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>35</th>\n",
              "      <td>0.001544</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>36</th>\n",
              "      <td>0.023339</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>37</th>\n",
              "      <td>0.014281</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>38</th>\n",
              "      <td>0.025345</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>39</th>\n",
              "      <td>0.008026</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>40</th>\n",
              "      <td>0.021972</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>41</th>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>42</th>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>43</th>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>44</th>\n",
              "      <td>0.001047</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>45</th>\n",
              "      <td>0.000739</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>46</th>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>47</th>\n",
              "      <td>0.008044</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>48</th>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>49</th>\n",
              "      <td>0.016428</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       score\n",
              "0   0.007252\n",
              "1   0.013396\n",
              "2   0.014913\n",
              "3   0.000000\n",
              "4   0.002265\n",
              "5   0.002011\n",
              "6   0.018354\n",
              "7   0.016569\n",
              "8   0.001047\n",
              "9   0.005303\n",
              "10  0.000642\n",
              "11  0.000000\n",
              "12  0.000000\n",
              "13  0.016382\n",
              "14  0.000000\n",
              "15  0.000000\n",
              "16  0.016178\n",
              "17  0.000000\n",
              "18  0.000000\n",
              "19  0.023111\n",
              "20  0.000000\n",
              "21  0.000000\n",
              "22  0.001396\n",
              "23  0.000000\n",
              "24  0.000000\n",
              "25  0.007167\n",
              "26  0.000000\n",
              "27  0.001047\n",
              "28  0.000000\n",
              "29  0.000000\n",
              "30  0.006040\n",
              "31  0.009930\n",
              "32  0.010082\n",
              "33  0.000000\n",
              "34  0.011088\n",
              "35  0.001544\n",
              "36  0.023339\n",
              "37  0.014281\n",
              "38  0.025345\n",
              "39  0.008026\n",
              "40  0.021972\n",
              "41  0.000000\n",
              "42  0.000000\n",
              "43  0.000000\n",
              "44  0.001047\n",
              "45  0.000739\n",
              "46  0.000000\n",
              "47  0.008044\n",
              "48  0.000000\n",
              "49  0.016428"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "noZNwjqVem40"
      },
      "source": [
        "## LambdaRank"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6ErTq3BSem40",
        "outputId": "75f324a5-1b68-4482-de2f-b682f557e3c2"
      },
      "source": [
        "!pip install LambdaRankNN\n",
        "from LambdaRankNN import LambdaRankNN\n",
        "\n",
        "#Generación de datos dummies\n",
        "X = np.array([[0.2, 0.3, 0.4],\n",
        "              [0.1, 0.7, 0.4],\n",
        "              [0.3, 0.4, 0.1],\n",
        "              [0.8, 0.4, 0.3],\n",
        "              [0.9, 0.35, 0.25]])\n",
        "y = np.array([0, 1, 0, 0, 2])\n",
        "qid = np.array([1, 1, 1, 2, 2])\n",
        "\n",
        "#Entrenamiento del modelo\n",
        "ranker = LambdaRankNN(input_size=X.shape[1], hidden_layer_sizes=(16,8,), \n",
        "                      activation=('relu', 'relu',), \n",
        "                      solver='adam')\n",
        "ranker.fit(X, y, qid, epochs=5)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: LambdaRankNN in /usr/local/lib/python3.7/dist-packages (0.1.1)\n",
            "Epoch 1/5\n",
            "1/1 [==============================] - 0s 445ms/step - loss: 0.2037\n",
            "Epoch 2/5\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.2033\n",
            "Epoch 3/5\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.2028\n",
            "Epoch 4/5\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.2024\n",
            "Epoch 5/5\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.2019\n",
            "ndcg: 0.8154648767857287\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9Y250u7-nmRP",
        "outputId": "fb5b07c8-f664-415d-e30c-a175f5ce620f"
      },
      "source": [
        "y_pred = ranker.predict(X)\n",
        "ranker.evaluate(X, y, qid, eval_at=2)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ndcg@2: 0.8154648767857287\n"
          ]
        }
      ]
    }
  ]
}