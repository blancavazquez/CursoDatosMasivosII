{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    },
    "colab": {
      "name": "4e_learningToRank.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/blancavazquez/CursoDatosMasivosII/blob/master/notebooks/4e_learningToRank.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZbM6Jzkbem4q"
      },
      "source": [
        "## Algoritmos learning to rank\n",
        "\n",
        "El objetivo de esta libreta es estudiar los algoritmos de learning to rank en sistemas de recomendación\n",
        "\n",
        "[Créditos](https://github.com/liyinxiao/rankerNN2pmml)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lB2Z-XlKem4u"
      },
      "source": [
        "## RankNet"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8DI5uftxem4u"
      },
      "source": [
        "import keras\n",
        "from keras import backend as K\n",
        "from keras.layers import Activation, Dense, Input, Subtract\n",
        "from keras.models import Model\n",
        "import random\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9ZIYP3bVem4w",
        "outputId": "33fb74a2-ac91-477a-9c3c-364bba85a5ba"
      },
      "source": [
        "\"\"\"Generación de datos dummies\"\"\"\n",
        "INPUT_DIM = 3\n",
        "\n",
        "#se definen los objetos a comparar\n",
        "X1 = 2 * np.random.uniform(size=(50, INPUT_DIM)) #Objeto 1\n",
        "X2 = np.random.uniform(size=(50, INPUT_DIM)) #Objeto 2\n",
        "Y = [random.randint(0,1) for _ in range(50)]\n",
        "\n",
        "print(\"Tamaño de X1\",X1.shape)\n",
        "print(\"Tamaño de X2\",X2.shape)\n",
        "print(\"Tamaño de Y\",len(Y))"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tamaño de X1 (50, 3)\n",
            "Tamaño de X2 (50, 3)\n",
            "Tamaño de Y 50\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2XIGpnstem4y"
      },
      "source": [
        "# Transformación de los datos\n",
        "mms = MinMaxScaler() #default=(0, 1)\n",
        "mms.fit(np.concatenate((X1, X2), axis=0))\n",
        "X1 = mms.transform(X1)\n",
        "X2 = mms.transform(X2)\n",
        "Y = np.asarray(Y)"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "PsHGiq3kmJrR",
        "outputId": "1b6f5f19-5b80-448a-ddf2-0cd4e5835488"
      },
      "source": [
        "#Visualizando la entrada\n",
        "df_input = pd.DataFrame(X1, columns = ['Feature1', 'Feature2', 'Feature3'])\n",
        "df_input"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Feature1</th>\n",
              "      <th>Feature2</th>\n",
              "      <th>Feature3</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.410262</td>\n",
              "      <td>0.326021</td>\n",
              "      <td>0.322110</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.208488</td>\n",
              "      <td>0.532209</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.615974</td>\n",
              "      <td>0.769591</td>\n",
              "      <td>0.986998</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.075810</td>\n",
              "      <td>0.934574</td>\n",
              "      <td>0.795487</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.731731</td>\n",
              "      <td>0.293337</td>\n",
              "      <td>0.315694</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>0.124437</td>\n",
              "      <td>0.415263</td>\n",
              "      <td>0.869960</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>0.732372</td>\n",
              "      <td>0.597563</td>\n",
              "      <td>0.312634</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>0.816447</td>\n",
              "      <td>0.826618</td>\n",
              "      <td>0.837089</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>0.585566</td>\n",
              "      <td>0.983770</td>\n",
              "      <td>0.292767</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>0.731872</td>\n",
              "      <td>0.816791</td>\n",
              "      <td>0.370186</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>0.375461</td>\n",
              "      <td>0.116513</td>\n",
              "      <td>0.982624</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>0.170586</td>\n",
              "      <td>0.187352</td>\n",
              "      <td>0.799285</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>0.522486</td>\n",
              "      <td>0.233661</td>\n",
              "      <td>0.886340</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>0.550054</td>\n",
              "      <td>0.686137</td>\n",
              "      <td>0.545970</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>0.571787</td>\n",
              "      <td>0.705155</td>\n",
              "      <td>0.522765</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>0.977633</td>\n",
              "      <td>0.880918</td>\n",
              "      <td>0.589520</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>0.124763</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.079209</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>0.387508</td>\n",
              "      <td>0.255847</td>\n",
              "      <td>0.324341</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>0.203562</td>\n",
              "      <td>0.534019</td>\n",
              "      <td>0.896795</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>0.089180</td>\n",
              "      <td>0.526483</td>\n",
              "      <td>0.851865</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>0.436018</td>\n",
              "      <td>0.286948</td>\n",
              "      <td>0.512940</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>0.215738</td>\n",
              "      <td>0.666700</td>\n",
              "      <td>0.214547</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>0.355392</td>\n",
              "      <td>0.087629</td>\n",
              "      <td>0.551107</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>0.667696</td>\n",
              "      <td>0.882470</td>\n",
              "      <td>0.440546</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24</th>\n",
              "      <td>0.669385</td>\n",
              "      <td>0.161475</td>\n",
              "      <td>0.725580</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25</th>\n",
              "      <td>0.475761</td>\n",
              "      <td>0.805375</td>\n",
              "      <td>0.690928</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26</th>\n",
              "      <td>0.047206</td>\n",
              "      <td>0.706548</td>\n",
              "      <td>0.756253</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27</th>\n",
              "      <td>0.437735</td>\n",
              "      <td>0.803850</td>\n",
              "      <td>0.071694</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28</th>\n",
              "      <td>0.523869</td>\n",
              "      <td>0.470084</td>\n",
              "      <td>0.566501</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29</th>\n",
              "      <td>0.890817</td>\n",
              "      <td>0.044524</td>\n",
              "      <td>0.143123</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30</th>\n",
              "      <td>0.074361</td>\n",
              "      <td>0.148369</td>\n",
              "      <td>0.403241</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>31</th>\n",
              "      <td>0.773435</td>\n",
              "      <td>0.544048</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>32</th>\n",
              "      <td>0.393349</td>\n",
              "      <td>0.146992</td>\n",
              "      <td>0.964755</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>33</th>\n",
              "      <td>0.059602</td>\n",
              "      <td>0.886345</td>\n",
              "      <td>0.756582</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>34</th>\n",
              "      <td>0.887864</td>\n",
              "      <td>0.299038</td>\n",
              "      <td>0.395824</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>35</th>\n",
              "      <td>0.680671</td>\n",
              "      <td>0.089616</td>\n",
              "      <td>0.622438</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>36</th>\n",
              "      <td>0.123579</td>\n",
              "      <td>0.316896</td>\n",
              "      <td>0.260454</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>37</th>\n",
              "      <td>0.330249</td>\n",
              "      <td>0.059375</td>\n",
              "      <td>0.454363</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>38</th>\n",
              "      <td>0.445794</td>\n",
              "      <td>0.761927</td>\n",
              "      <td>0.588801</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>39</th>\n",
              "      <td>0.251956</td>\n",
              "      <td>0.448748</td>\n",
              "      <td>0.937116</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>40</th>\n",
              "      <td>0.842626</td>\n",
              "      <td>0.873804</td>\n",
              "      <td>0.950040</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>41</th>\n",
              "      <td>0.066285</td>\n",
              "      <td>0.349490</td>\n",
              "      <td>0.243897</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>42</th>\n",
              "      <td>0.710612</td>\n",
              "      <td>0.019578</td>\n",
              "      <td>0.861620</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>43</th>\n",
              "      <td>0.593604</td>\n",
              "      <td>0.623885</td>\n",
              "      <td>0.012131</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>44</th>\n",
              "      <td>0.721440</td>\n",
              "      <td>0.850804</td>\n",
              "      <td>0.959046</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>45</th>\n",
              "      <td>0.604066</td>\n",
              "      <td>0.917086</td>\n",
              "      <td>0.377155</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>46</th>\n",
              "      <td>0.339255</td>\n",
              "      <td>0.933104</td>\n",
              "      <td>0.260448</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>47</th>\n",
              "      <td>0.283461</td>\n",
              "      <td>0.999096</td>\n",
              "      <td>0.337193</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>48</th>\n",
              "      <td>0.324836</td>\n",
              "      <td>0.896944</td>\n",
              "      <td>0.572503</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>49</th>\n",
              "      <td>0.059121</td>\n",
              "      <td>0.103824</td>\n",
              "      <td>0.116657</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    Feature1  Feature2  Feature3\n",
              "0   0.410262  0.326021  0.322110\n",
              "1   1.000000  0.208488  0.532209\n",
              "2   0.615974  0.769591  0.986998\n",
              "3   0.075810  0.934574  0.795487\n",
              "4   0.731731  0.293337  0.315694\n",
              "5   0.124437  0.415263  0.869960\n",
              "6   0.732372  0.597563  0.312634\n",
              "7   0.816447  0.826618  0.837089\n",
              "8   0.585566  0.983770  0.292767\n",
              "9   0.731872  0.816791  0.370186\n",
              "10  0.375461  0.116513  0.982624\n",
              "11  0.170586  0.187352  0.799285\n",
              "12  0.522486  0.233661  0.886340\n",
              "13  0.550054  0.686137  0.545970\n",
              "14  0.571787  0.705155  0.522765\n",
              "15  0.977633  0.880918  0.589520\n",
              "16  0.124763  1.000000  0.079209\n",
              "17  0.387508  0.255847  0.324341\n",
              "18  0.203562  0.534019  0.896795\n",
              "19  0.089180  0.526483  0.851865\n",
              "20  0.436018  0.286948  0.512940\n",
              "21  0.215738  0.666700  0.214547\n",
              "22  0.355392  0.087629  0.551107\n",
              "23  0.667696  0.882470  0.440546\n",
              "24  0.669385  0.161475  0.725580\n",
              "25  0.475761  0.805375  0.690928\n",
              "26  0.047206  0.706548  0.756253\n",
              "27  0.437735  0.803850  0.071694\n",
              "28  0.523869  0.470084  0.566501\n",
              "29  0.890817  0.044524  0.143123\n",
              "30  0.074361  0.148369  0.403241\n",
              "31  0.773435  0.544048  1.000000\n",
              "32  0.393349  0.146992  0.964755\n",
              "33  0.059602  0.886345  0.756582\n",
              "34  0.887864  0.299038  0.395824\n",
              "35  0.680671  0.089616  0.622438\n",
              "36  0.123579  0.316896  0.260454\n",
              "37  0.330249  0.059375  0.454363\n",
              "38  0.445794  0.761927  0.588801\n",
              "39  0.251956  0.448748  0.937116\n",
              "40  0.842626  0.873804  0.950040\n",
              "41  0.066285  0.349490  0.243897\n",
              "42  0.710612  0.019578  0.861620\n",
              "43  0.593604  0.623885  0.012131\n",
              "44  0.721440  0.850804  0.959046\n",
              "45  0.604066  0.917086  0.377155\n",
              "46  0.339255  0.933104  0.260448\n",
              "47  0.283461  0.999096  0.337193\n",
              "48  0.324836  0.896944  0.572503\n",
              "49  0.059121  0.103824  0.116657"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kg-bWpcVem4x"
      },
      "source": [
        "def RankNet_model(input_shape):\n",
        "    \"\"\"Construcción de la red neuronal\"\"\"\n",
        "    h1 = Dense(4, activation=\"relu\", name='Relu_layer1') #red completamente conectada\n",
        "    h2 = Dense(2, activation='relu', name='Relu_layer2')\n",
        "    h3 = Dense(1, activation='linear', name='Identity_layer')\n",
        "    # Objeto 1 a comparar\n",
        "    input1 = Input(shape=(input_shape,), name='Input_layer1')\n",
        "    x1 = h1(input1)\n",
        "    x1 = h2(x1)\n",
        "    x1 = h3(x1)\n",
        "    # Objeto 2 a comparar\n",
        "    input2 = Input(shape=(input_shape,), name='Input_layer2')\n",
        "    x2 = h1(input2)\n",
        "    x2 = h2(x2)\n",
        "    x2 = h3(x2)\n",
        "    # Capa de comparación\n",
        "    subtracted = Subtract(name='Subtract_layer')([x1, x2])\n",
        "    # Función de activación\n",
        "    out = Activation('sigmoid', name='Activation_layer')(subtracted)\n",
        "    # Modelo\n",
        "    model = Model(inputs=[input1, input2], outputs=out)\n",
        "    return model"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GRPDymtBem4x",
        "outputId": "22795739-e17c-4ad4-acf7-d6b8ce7cea27"
      },
      "source": [
        "model = RankNet_model(INPUT_DIM)\n",
        "print(model.summary())"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "Input_layer1 (InputLayer)       [(None, 3)]          0                                            \n",
            "__________________________________________________________________________________________________\n",
            "Input_layer2 (InputLayer)       [(None, 3)]          0                                            \n",
            "__________________________________________________________________________________________________\n",
            "Relu_layer1 (Dense)             (None, 4)            16          Input_layer1[0][0]               \n",
            "                                                                 Input_layer2[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "Relu_layer2 (Dense)             (None, 2)            10          Relu_layer1[0][0]                \n",
            "                                                                 Relu_layer1[1][0]                \n",
            "__________________________________________________________________________________________________\n",
            "Identity_layer (Dense)          (None, 1)            3           Relu_layer2[0][0]                \n",
            "                                                                 Relu_layer2[1][0]                \n",
            "__________________________________________________________________________________________________\n",
            "Subtract_layer (Subtract)       (None, 1)            0           Identity_layer[0][0]             \n",
            "                                                                 Identity_layer[1][0]             \n",
            "__________________________________________________________________________________________________\n",
            "Activation_layer (Activation)   (None, 1)            0           Subtract_layer[0][0]             \n",
            "==================================================================================================\n",
            "Total params: 29\n",
            "Trainable params: 29\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n",
            "None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t1-ubJa3em4y",
        "outputId": "9c363380-8104-4837-c47c-f3400b03862d"
      },
      "source": [
        "# Entrenamiento del modelo\n",
        "model.compile(optimizer=\"adam\", loss=\"binary_crossentropy\")\n",
        "model.fit([X1,X2], Y, batch_size=10, epochs=5, verbose=1)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "5/5 [==============================] - 1s 3ms/step - loss: 0.7107\n",
            "Epoch 2/5\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.7098\n",
            "Epoch 3/5\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.7091\n",
            "Epoch 4/5\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.7084\n",
            "Epoch 5/5\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.7078\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f51cd5a4a50>"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SEkirMRygY91"
      },
      "source": [
        "#Salida del modelo\n",
        "get_ranker_output = K.function([model.layers[0].input], [model.layers[-3].get_output_at(0)])\n",
        "Ranker_output = get_ranker_output([X1])[0]"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "gRw165gimRDZ",
        "outputId": "726c2348-3eb1-498c-b8fe-1c13eb1894dd"
      },
      "source": [
        "#Visualizando la salida\n",
        "df_output = pd.DataFrame(Ranker_output, columns = ['score'])\n",
        "df_output"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>score</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.266081</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.347785</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.746087</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.757536</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.220885</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>0.592542</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>0.304069</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>0.678067</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>0.428867</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>0.408297</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>0.514286</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>0.467265</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>0.499817</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>0.502095</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>0.490541</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>0.536738</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>0.417040</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>0.242258</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>0.644703</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>0.628795</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>0.343118</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>0.327320</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>0.292397</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>0.481178</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24</th>\n",
              "      <td>0.381494</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25</th>\n",
              "      <td>0.625068</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26</th>\n",
              "      <td>0.653635</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27</th>\n",
              "      <td>0.251432</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28</th>\n",
              "      <td>0.432268</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29</th>\n",
              "      <td>0.186010</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30</th>\n",
              "      <td>0.265046</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>31</th>\n",
              "      <td>0.654073</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>32</th>\n",
              "      <td>0.515676</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>33</th>\n",
              "      <td>0.721296</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>34</th>\n",
              "      <td>0.278037</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>35</th>\n",
              "      <td>0.303031</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>36</th>\n",
              "      <td>0.255018</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>37</th>\n",
              "      <td>0.235995</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>38</th>\n",
              "      <td>0.560611</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>39</th>\n",
              "      <td>0.628235</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>40</th>\n",
              "      <td>0.749578</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>41</th>\n",
              "      <td>0.263832</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>42</th>\n",
              "      <td>0.391158</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>43</th>\n",
              "      <td>0.138751</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>44</th>\n",
              "      <td>0.754878</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>45</th>\n",
              "      <td>0.459538</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>46</th>\n",
              "      <td>0.423312</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>47</th>\n",
              "      <td>0.499299</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>48</th>\n",
              "      <td>0.611947</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>49</th>\n",
              "      <td>0.108174</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       score\n",
              "0   0.266081\n",
              "1   0.347785\n",
              "2   0.746087\n",
              "3   0.757536\n",
              "4   0.220885\n",
              "5   0.592542\n",
              "6   0.304069\n",
              "7   0.678067\n",
              "8   0.428867\n",
              "9   0.408297\n",
              "10  0.514286\n",
              "11  0.467265\n",
              "12  0.499817\n",
              "13  0.502095\n",
              "14  0.490541\n",
              "15  0.536738\n",
              "16  0.417040\n",
              "17  0.242258\n",
              "18  0.644703\n",
              "19  0.628795\n",
              "20  0.343118\n",
              "21  0.327320\n",
              "22  0.292397\n",
              "23  0.481178\n",
              "24  0.381494\n",
              "25  0.625068\n",
              "26  0.653635\n",
              "27  0.251432\n",
              "28  0.432268\n",
              "29  0.186010\n",
              "30  0.265046\n",
              "31  0.654073\n",
              "32  0.515676\n",
              "33  0.721296\n",
              "34  0.278037\n",
              "35  0.303031\n",
              "36  0.255018\n",
              "37  0.235995\n",
              "38  0.560611\n",
              "39  0.628235\n",
              "40  0.749578\n",
              "41  0.263832\n",
              "42  0.391158\n",
              "43  0.138751\n",
              "44  0.754878\n",
              "45  0.459538\n",
              "46  0.423312\n",
              "47  0.499299\n",
              "48  0.611947\n",
              "49  0.108174"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "noZNwjqVem40"
      },
      "source": [
        "## LambdaRank"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6ErTq3BSem40",
        "outputId": "1b57196b-189a-49b1-a920-dfb13074f55d"
      },
      "source": [
        "!pip install LambdaRankNN\n",
        "from LambdaRankNN import LambdaRankNN\n",
        "\n",
        "#Generación de datos dummies\n",
        "X = np.array([[0.2, 0.3, 0.4],\n",
        "              [0.1, 0.7, 0.4],\n",
        "              [0.3, 0.4, 0.1],\n",
        "              [0.8, 0.4, 0.3],\n",
        "              [0.9, 0.35, 0.25]])\n",
        "y = np.array([0, 1, 0, 0, 2])\n",
        "qid = np.array([1, 1, 1, 2, 2])\n",
        "\n",
        "#Entrenamiento del modelo\n",
        "ranker = LambdaRankNN(input_size=X.shape[1], hidden_layer_sizes=(16,8,), \n",
        "                      activation=('relu', 'relu',), \n",
        "                      solver='adam')\n",
        "ranker.fit(X, y, qid, epochs=5)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: LambdaRankNN in /usr/local/lib/python3.7/dist-packages (0.1.1)\n",
            "Epoch 1/5\n",
            "1/1 [==============================] - 1s 529ms/step - loss: 0.2081\n",
            "Epoch 2/5\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.2077\n",
            "Epoch 3/5\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.2072\n",
            "Epoch 4/5\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.2068\n",
            "Epoch 5/5\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.2064\n",
            "ndcg: 0.5654648767857287\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9Y250u7-nmRP",
        "outputId": "da6e0bde-52e7-4c93-fe98-6337b42ced35"
      },
      "source": [
        "y_pred = ranker.predict(X)\n",
        "ranker.evaluate(X, y, qid, eval_at=2)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ndcg@2: 0.3154648767857287\n"
          ]
        }
      ]
    }
  ]
}