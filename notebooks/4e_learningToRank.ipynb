{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    },
    "colab": {
      "name": "4e_learningToRank.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/blancavazquez/CursoDatosMasivosII/blob/master/notebooks/4e_learningToRank.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZbM6Jzkbem4q"
      },
      "source": [
        "## Algoritmos learning to rank\n",
        "\n",
        "El objetivo de esta libreta es estudiar los algoritmos de learning to rank en sistemas de recomendación\n",
        "\n",
        "[Créditos](https://github.com/liyinxiao/rankerNN2pmml)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lB2Z-XlKem4u"
      },
      "source": [
        "## RankNet"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8DI5uftxem4u"
      },
      "source": [
        "import keras\n",
        "from keras import backend as K\n",
        "from keras.layers import Activation, Dense, Input, Subtract\n",
        "from keras.models import Model\n",
        "import random\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9ZIYP3bVem4w",
        "outputId": "b5a4d107-c491-44ed-d046-c47a7fab98d2"
      },
      "source": [
        "\"\"\"Generación de datos dummies\"\"\"\n",
        "INPUT_DIM = 3\n",
        "\n",
        "#se definen los objetos a comparar\n",
        "X1 = 2 * np.random.uniform(size=(50, INPUT_DIM)) #Objeto 1\n",
        "X2 = np.random.uniform(size=(50, INPUT_DIM)) #Objeto 2\n",
        "Y = [random.randint(0,1) for _ in range(50)]\n",
        "\n",
        "print(\"Tamaño de X1\",X1.shape)\n",
        "print(\"Tamaño de X2\",X2.shape)\n",
        "print(\"Tamaño de Y\",len(Y))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tamaño de X1 (50, 3)\n",
            "Tamaño de X2 (50, 3)\n",
            "Tamaño de Y 50\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2XIGpnstem4y"
      },
      "source": [
        "# Transformación de los datos\n",
        "mms = MinMaxScaler() #default=(0, 1)\n",
        "mms.fit(np.concatenate((X1, X2), axis=0))\n",
        "X1 = mms.transform(X1)\n",
        "X2 = mms.transform(X2)\n",
        "Y = np.asarray(Y)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "PsHGiq3kmJrR",
        "outputId": "3decd662-d5f9-4ab8-ddcb-a47378c0f6ab"
      },
      "source": [
        "#Visualizando la entrada\n",
        "df_input = pd.DataFrame(X1, columns = ['Feature1', 'Feature2', 'Feature3'])\n",
        "df_input"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Feature1</th>\n",
              "      <th>Feature2</th>\n",
              "      <th>Feature3</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.235954</td>\n",
              "      <td>0.171641</td>\n",
              "      <td>0.146817</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.748380</td>\n",
              "      <td>0.363056</td>\n",
              "      <td>0.815422</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.305907</td>\n",
              "      <td>0.450836</td>\n",
              "      <td>0.968545</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.848680</td>\n",
              "      <td>0.900038</td>\n",
              "      <td>0.839035</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.113283</td>\n",
              "      <td>0.354020</td>\n",
              "      <td>0.843931</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>0.217854</td>\n",
              "      <td>0.290997</td>\n",
              "      <td>0.295289</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>0.856920</td>\n",
              "      <td>0.660012</td>\n",
              "      <td>0.081989</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>0.647708</td>\n",
              "      <td>0.105392</td>\n",
              "      <td>0.284839</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>0.032633</td>\n",
              "      <td>0.484461</td>\n",
              "      <td>0.123438</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>0.591712</td>\n",
              "      <td>0.012010</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>0.965799</td>\n",
              "      <td>0.205081</td>\n",
              "      <td>0.611965</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>0.142097</td>\n",
              "      <td>0.218180</td>\n",
              "      <td>0.169265</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>0.807816</td>\n",
              "      <td>0.541448</td>\n",
              "      <td>0.532733</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>0.267424</td>\n",
              "      <td>0.364791</td>\n",
              "      <td>0.928772</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>0.009662</td>\n",
              "      <td>0.320506</td>\n",
              "      <td>0.539366</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>0.247869</td>\n",
              "      <td>0.523318</td>\n",
              "      <td>0.880881</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>0.826619</td>\n",
              "      <td>0.288152</td>\n",
              "      <td>0.549059</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>0.597814</td>\n",
              "      <td>0.480061</td>\n",
              "      <td>0.752612</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>0.550004</td>\n",
              "      <td>0.411811</td>\n",
              "      <td>0.656870</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>0.297349</td>\n",
              "      <td>0.021306</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>0.115014</td>\n",
              "      <td>0.474825</td>\n",
              "      <td>0.698446</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>0.508630</td>\n",
              "      <td>0.430548</td>\n",
              "      <td>0.444559</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>0.039441</td>\n",
              "      <td>0.051718</td>\n",
              "      <td>0.140105</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>0.311622</td>\n",
              "      <td>0.779245</td>\n",
              "      <td>0.838014</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24</th>\n",
              "      <td>0.726076</td>\n",
              "      <td>0.666154</td>\n",
              "      <td>0.725755</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25</th>\n",
              "      <td>0.357154</td>\n",
              "      <td>0.295951</td>\n",
              "      <td>0.451520</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26</th>\n",
              "      <td>0.443862</td>\n",
              "      <td>0.950237</td>\n",
              "      <td>0.429697</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27</th>\n",
              "      <td>0.703550</td>\n",
              "      <td>0.134474</td>\n",
              "      <td>0.861322</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28</th>\n",
              "      <td>0.121316</td>\n",
              "      <td>0.910425</td>\n",
              "      <td>0.297852</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29</th>\n",
              "      <td>0.829416</td>\n",
              "      <td>0.649760</td>\n",
              "      <td>0.530140</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30</th>\n",
              "      <td>0.440260</td>\n",
              "      <td>0.124354</td>\n",
              "      <td>0.029532</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>31</th>\n",
              "      <td>0.430945</td>\n",
              "      <td>0.688407</td>\n",
              "      <td>0.877258</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>32</th>\n",
              "      <td>0.999853</td>\n",
              "      <td>0.496145</td>\n",
              "      <td>0.730488</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>33</th>\n",
              "      <td>0.658008</td>\n",
              "      <td>0.004109</td>\n",
              "      <td>0.026316</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>34</th>\n",
              "      <td>0.384366</td>\n",
              "      <td>0.901732</td>\n",
              "      <td>0.630132</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>35</th>\n",
              "      <td>0.055831</td>\n",
              "      <td>0.430773</td>\n",
              "      <td>0.658308</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>36</th>\n",
              "      <td>0.699548</td>\n",
              "      <td>0.726026</td>\n",
              "      <td>0.272626</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>37</th>\n",
              "      <td>0.684805</td>\n",
              "      <td>0.193595</td>\n",
              "      <td>0.761270</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>38</th>\n",
              "      <td>0.220325</td>\n",
              "      <td>0.350480</td>\n",
              "      <td>0.577729</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>39</th>\n",
              "      <td>0.347502</td>\n",
              "      <td>0.815024</td>\n",
              "      <td>0.785029</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>40</th>\n",
              "      <td>0.166252</td>\n",
              "      <td>0.074845</td>\n",
              "      <td>0.804137</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>41</th>\n",
              "      <td>0.244513</td>\n",
              "      <td>0.066367</td>\n",
              "      <td>0.158830</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>42</th>\n",
              "      <td>0.064434</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.574420</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>43</th>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.435869</td>\n",
              "      <td>0.503133</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>44</th>\n",
              "      <td>0.387981</td>\n",
              "      <td>0.215243</td>\n",
              "      <td>0.117045</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>45</th>\n",
              "      <td>0.519915</td>\n",
              "      <td>0.399531</td>\n",
              "      <td>0.802786</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>46</th>\n",
              "      <td>0.996793</td>\n",
              "      <td>0.273669</td>\n",
              "      <td>0.990770</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>47</th>\n",
              "      <td>0.217615</td>\n",
              "      <td>0.195848</td>\n",
              "      <td>0.451526</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>48</th>\n",
              "      <td>0.906853</td>\n",
              "      <td>0.291416</td>\n",
              "      <td>0.554293</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>49</th>\n",
              "      <td>0.769796</td>\n",
              "      <td>0.810350</td>\n",
              "      <td>0.439501</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    Feature1  Feature2  Feature3\n",
              "0   0.235954  0.171641  0.146817\n",
              "1   0.748380  0.363056  0.815422\n",
              "2   0.305907  0.450836  0.968545\n",
              "3   0.848680  0.900038  0.839035\n",
              "4   0.113283  0.354020  0.843931\n",
              "5   0.217854  0.290997  0.295289\n",
              "6   0.856920  0.660012  0.081989\n",
              "7   0.647708  0.105392  0.284839\n",
              "8   0.032633  0.484461  0.123438\n",
              "9   0.591712  0.012010  1.000000\n",
              "10  0.965799  0.205081  0.611965\n",
              "11  0.142097  0.218180  0.169265\n",
              "12  0.807816  0.541448  0.532733\n",
              "13  0.267424  0.364791  0.928772\n",
              "14  0.009662  0.320506  0.539366\n",
              "15  0.247869  0.523318  0.880881\n",
              "16  0.826619  0.288152  0.549059\n",
              "17  0.597814  0.480061  0.752612\n",
              "18  0.550004  0.411811  0.656870\n",
              "19  0.297349  0.021306  0.000000\n",
              "20  0.115014  0.474825  0.698446\n",
              "21  0.508630  0.430548  0.444559\n",
              "22  0.039441  0.051718  0.140105\n",
              "23  0.311622  0.779245  0.838014\n",
              "24  0.726076  0.666154  0.725755\n",
              "25  0.357154  0.295951  0.451520\n",
              "26  0.443862  0.950237  0.429697\n",
              "27  0.703550  0.134474  0.861322\n",
              "28  0.121316  0.910425  0.297852\n",
              "29  0.829416  0.649760  0.530140\n",
              "30  0.440260  0.124354  0.029532\n",
              "31  0.430945  0.688407  0.877258\n",
              "32  0.999853  0.496145  0.730488\n",
              "33  0.658008  0.004109  0.026316\n",
              "34  0.384366  0.901732  0.630132\n",
              "35  0.055831  0.430773  0.658308\n",
              "36  0.699548  0.726026  0.272626\n",
              "37  0.684805  0.193595  0.761270\n",
              "38  0.220325  0.350480  0.577729\n",
              "39  0.347502  0.815024  0.785029\n",
              "40  0.166252  0.074845  0.804137\n",
              "41  0.244513  0.066367  0.158830\n",
              "42  0.064434  1.000000  0.574420\n",
              "43  1.000000  0.435869  0.503133\n",
              "44  0.387981  0.215243  0.117045\n",
              "45  0.519915  0.399531  0.802786\n",
              "46  0.996793  0.273669  0.990770\n",
              "47  0.217615  0.195848  0.451526\n",
              "48  0.906853  0.291416  0.554293\n",
              "49  0.769796  0.810350  0.439501"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kg-bWpcVem4x"
      },
      "source": [
        "def RankNet_model(input_shape):\n",
        "    \"\"\"Construcción de la red neuronal\"\"\"\n",
        "    h1 = Dense(4, activation=\"relu\", name='Relu_layer1') #red completamente conectada\n",
        "    h2 = Dense(2, activation='relu', name='Relu_layer2')\n",
        "    h3 = Dense(1, activation='linear', name='Identity_layer')\n",
        "    # Objeto 1 a comparar\n",
        "    input1 = Input(shape=(input_shape,), name='Input_layer1')\n",
        "    x1 = h1(input1)\n",
        "    x1 = h2(x1)\n",
        "    x1 = h3(x1)\n",
        "    # Objeto 2 a comparar\n",
        "    input2 = Input(shape=(input_shape,), name='Input_layer2')\n",
        "    x2 = h1(input2)\n",
        "    x2 = h2(x2)\n",
        "    x2 = h3(x2)\n",
        "    # Capa de comparación\n",
        "    subtracted = Subtract(name='Subtract_layer')([x1, x2])\n",
        "    # Función de activación\n",
        "    out = Activation('sigmoid', name='Activation_layer')(subtracted)\n",
        "    # Modelo\n",
        "    model = Model(inputs=[input1, input2], outputs=out)\n",
        "    return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GRPDymtBem4x",
        "outputId": "48cc844d-4cdd-4d50-97e1-1357082a7bbd"
      },
      "source": [
        "model = RankNet_model(INPUT_DIM)\n",
        "print(model.summary())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "Input_layer1 (InputLayer)       [(None, 3)]          0                                            \n",
            "__________________________________________________________________________________________________\n",
            "Input_layer2 (InputLayer)       [(None, 3)]          0                                            \n",
            "__________________________________________________________________________________________________\n",
            "Relu_layer1 (Dense)             (None, 4)            16          Input_layer1[0][0]               \n",
            "                                                                 Input_layer2[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "Relu_layer2 (Dense)             (None, 2)            10          Relu_layer1[0][0]                \n",
            "                                                                 Relu_layer1[1][0]                \n",
            "__________________________________________________________________________________________________\n",
            "Identity_layer (Dense)          (None, 1)            3           Relu_layer2[0][0]                \n",
            "                                                                 Relu_layer2[1][0]                \n",
            "__________________________________________________________________________________________________\n",
            "Subtract_layer (Subtract)       (None, 1)            0           Identity_layer[0][0]             \n",
            "                                                                 Identity_layer[1][0]             \n",
            "__________________________________________________________________________________________________\n",
            "Activation_layer (Activation)   (None, 1)            0           Subtract_layer[0][0]             \n",
            "==================================================================================================\n",
            "Total params: 29\n",
            "Trainable params: 29\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n",
            "None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t1-ubJa3em4y",
        "outputId": "a80345d5-065b-407f-cfb9-facfec9bc3c7"
      },
      "source": [
        "# Entrenamiento del modelo\n",
        "model.compile(optimizer=\"adam\", loss=\"binary_crossentropy\")\n",
        "model.fit([X1,X2], Y, batch_size=10, epochs=5, verbose=1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.6959\n",
            "Epoch 2/5\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.6952\n",
            "Epoch 3/5\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 0.6950\n",
            "Epoch 4/5\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.6944\n",
            "Epoch 5/5\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 0.6942\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f3bf728ce50>"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SEkirMRygY91"
      },
      "source": [
        "#Salida del modelo\n",
        "get_ranker_output = K.function([model.layers[0].input], [model.layers[-3].get_output_at(0)])\n",
        "Ranker_output = get_ranker_output([X1])[0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "gRw165gimRDZ",
        "outputId": "f5c60f1a-7abd-44f9-b016-c41a9475ae66"
      },
      "source": [
        "#Visualizando la salida\n",
        "df_output = pd.DataFrame(Ranker_output, columns = ['score'])\n",
        "df_output"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>score</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>0.021078</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24</th>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25</th>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26</th>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27</th>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28</th>\n",
              "      <td>0.042872</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29</th>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30</th>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>31</th>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>32</th>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>33</th>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>34</th>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>35</th>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>36</th>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>37</th>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>38</th>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>39</th>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>40</th>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>41</th>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>42</th>\n",
              "      <td>0.016444</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>43</th>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>44</th>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>45</th>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>46</th>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>47</th>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>48</th>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>49</th>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       score\n",
              "0   0.000000\n",
              "1   0.000000\n",
              "2   0.000000\n",
              "3   0.000000\n",
              "4   0.000000\n",
              "5   0.000000\n",
              "6   0.000000\n",
              "7   0.000000\n",
              "8   0.021078\n",
              "9   0.000000\n",
              "10  0.000000\n",
              "11  0.000000\n",
              "12  0.000000\n",
              "13  0.000000\n",
              "14  0.000000\n",
              "15  0.000000\n",
              "16  0.000000\n",
              "17  0.000000\n",
              "18  0.000000\n",
              "19  0.000000\n",
              "20  0.000000\n",
              "21  0.000000\n",
              "22  0.000000\n",
              "23  0.000000\n",
              "24  0.000000\n",
              "25  0.000000\n",
              "26  0.000000\n",
              "27  0.000000\n",
              "28  0.042872\n",
              "29  0.000000\n",
              "30  0.000000\n",
              "31  0.000000\n",
              "32  0.000000\n",
              "33  0.000000\n",
              "34  0.000000\n",
              "35  0.000000\n",
              "36  0.000000\n",
              "37  0.000000\n",
              "38  0.000000\n",
              "39  0.000000\n",
              "40  0.000000\n",
              "41  0.000000\n",
              "42  0.016444\n",
              "43  0.000000\n",
              "44  0.000000\n",
              "45  0.000000\n",
              "46  0.000000\n",
              "47  0.000000\n",
              "48  0.000000\n",
              "49  0.000000"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "noZNwjqVem40"
      },
      "source": [
        "## LambdaRank"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6ErTq3BSem40",
        "outputId": "ddd9f355-af94-466d-d215-990b09e7b9e1"
      },
      "source": [
        "!pip install LambdaRankNN\n",
        "from LambdaRankNN import LambdaRankNN\n",
        "\n",
        "#Generación de datos dummies\n",
        "X = np.array([[0.2, 0.3, 0.4],\n",
        "              [0.1, 0.7, 0.4],\n",
        "              [0.3, 0.4, 0.1],\n",
        "              [0.8, 0.4, 0.3],\n",
        "              [0.9, 0.35, 0.25]])\n",
        "y = np.array([0, 1, 0, 0, 2])\n",
        "qid = np.array([1, 1, 1, 2, 2])\n",
        "\n",
        "#Entrenamiento del modelo\n",
        "ranker = LambdaRankNN(input_size=X.shape[1], hidden_layer_sizes=(16,8,), \n",
        "                      activation=('relu', 'relu',), \n",
        "                      solver='adam')\n",
        "ranker.fit(X, y, qid, epochs=5)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: LambdaRankNN in /usr/local/lib/python3.7/dist-packages (0.1.1)\n",
            "Epoch 1/5\n",
            "1/1 [==============================] - 0s 456ms/step - loss: 0.2085\n",
            "Epoch 2/5\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.2083\n",
            "Epoch 3/5\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.2080\n",
            "Epoch 4/5\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.2077\n",
            "Epoch 5/5\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.2075\n",
            "ndcg: 0.75\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9Y250u7-nmRP",
        "outputId": "42f8fd9b-0eee-4da4-a048-fa441c74f178"
      },
      "source": [
        "y_pred = ranker.predict(X)\n",
        "ranker.evaluate(X, y, qid, eval_at=2)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ndcg@2: 0.5\n"
          ]
        }
      ]
    }
  ]
}